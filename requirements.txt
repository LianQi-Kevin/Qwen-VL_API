# Qwen-VL
transformers==4.32.0
accelerate
tiktoken
einops
transformers_stream_generator==0.0.4
scipy
pillow
tensorboard
matplotlib

# fastapi
pydantic~=2.6.1
fastapi~=0.109.2
uvicorn[standard]~=0.27.1
# /v1/files
aiofiles
aiocron
python-multipart
SQLAlchemy
# /v1/chat
requests~=2.31.0

# torch 2.2.0 for cuda 11.8
--extra-index-url https://download.pytorch.org/whl/cu118
torch~=2.2.0
torchvision

# Qwen-VL int4-Optimum
optimum
# with cuda 11.8, if cuda 12.0, not need to add --extra-index-url
--extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/
auto-gptq
